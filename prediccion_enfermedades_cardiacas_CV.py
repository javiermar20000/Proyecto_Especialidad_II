import pandas as pd                         # Importa la biblioteca pandas y la asigna al alias 'pd' para manipulaci√≥n de datos tabulares
import numpy as np                          # Importa la biblioteca numpy con el alias 'np' para operaciones num√©ricas y manejo de arrays
import joblib                               # Importa joblib para guardar y cargar modelos entrenados u otros objetos de Python
import matplotlib.pyplot as plt             # Importa la biblioteca matplotlib para visualizaci√≥n de gr√°ficos, asign√°ndola al alias 'plt'
from sklearn.model_selection import train_test_split, GridSearchCV  # Importa funciones de sklearn para dividir datos en entrenamiento/prueba y para realizar b√∫squeda de hiperpar√°metros
from sklearn.ensemble import RandomForestClassifier  # Importa el clasificador Random Forest del m√≥dulo ensemble de sklearn
from sklearn.linear_model import LogisticRegression  # Importa el modelo de Regresi√≥n Log√≠stica del m√≥dulo linear_model de sklearn
from sklearn.neighbors import KNeighborsClassifier  # Importa el clasificador k-vecinos m√°s cercanos del m√≥dulo neighbors
from sklearn.metrics import ( # Importa varias m√©tricas de evaluaci√≥n de modelos desde sklearn.metrics
    classification_report, confusion_matrix, accuracy_score, 
    roc_auc_score, roc_curve, auc
)  
from sklearn.preprocessing import StandardScaler  # Importa el escalador est√°ndar para normalizar caracter√≠sticas (media 0, desviaci√≥n est√°ndar 1)
import seaborn as sns                        # Importa la biblioteca seaborn, √∫til para gr√°ficos estad√≠sticos, con alias 'sns'
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.inspection import permutation_importance
import pandas as pd
import warnings                              # Importa el m√≥dulo warnings para gestionar advertencias del sistema
warnings.filterwarnings("ignore")           # Ignora las advertencias generadas durante la ejecuci√≥n del c√≥digo

# 1. Cargar el dataset
df = pd.read_csv('heart_attack_desease.csv')         # Lee el archivo CSV y lo carga en un DataFrame llamado 'df'

# 2. Revisar valores nulos
print("Valores nulos por columna:\n", df.isnull().sum())  # Muestra la cantidad de valores nulos por columna para verificar datos faltantes

# 3. Separar caracter√≠sticas (X) y etiqueta (y)
X = df.drop('target', axis=1)                        # Crea la matriz de caracter√≠sticas eliminando la columna 'target' del DataFrame
y = df['target']                                     # Define el vector objetivo (etiqueta) como la columna 'target'

# 4. Escalar los datos
scaler = StandardScaler()                            # Crea una instancia del escalador est√°ndar para normalizar las caracter√≠sticas
X_scaled = scaler.fit_transform(X)                   # Ajusta el escalador a los datos y transforma X para que tenga media 0 y varianza 1

# 5. Dividir en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y) # Divide los datos escalados en conjuntos de entrenamiento y prueba (80/20)
# 'random_state=42' asegura reproducibilidad
# 'stratify=y' mantiene la proporci√≥n de clases en ambos conjuntos

# 6. Buscar mejores hiperpar√°metros y entrenar modelos

# Logistic Regression
log_params = {'C': np.logspace(-3, 3, 10)}               # Define una grilla de valores para el hiperpar√°metro 'C' (regularizaci√≥n) en una escala logar√≠tmica
log_model = GridSearchCV(LogisticRegression(random_state=42), log_params, cv=5)  # Crea un GridSearchCV para buscar el mejor valor de 'C' usando validaci√≥n cruzada de 5 pliegues
log_model.fit(X_train, y_train)                         # Ajusta el modelo de regresi√≥n log√≠stica con los mejores hiperpar√°metros encontrados
log_best = log_model.best_estimator_                    # Extrae el mejor modelo (estimador) despu√©s de la b√∫squeda
log_pred = log_best.predict(X_test)                     # Realiza predicciones de clases sobre el conjunto de prueba
log_proba = log_best.predict_proba(X_test)[:, 1]        # Calcula las probabilidades predichas de la clase positiva (1) para m√©tricas como ROC AUC

# Funci√≥n para obtener el mejor modelo que no supere la restricci√≥n de precisi√≥n
def obtener_mejor_modelo_restringido(modelo_grid, nombre, X_train, y_train, max_precision=0.96):
    """
    Obtiene el mejor modelo que no supere la precisi√≥n m√°xima especificada
    """
    results = modelo_grid.cv_results_
    
    if nombre in ["KNN", "Random Forest"]:
        # Filtrar configuraciones que no superen la precisi√≥n m√°xima
        valid_indices = [i for i, score in enumerate(results['mean_test_score']) if score <= max_precision]
        
        if len(valid_indices) == 0:
            print(f"‚ö†Ô∏è Advertencia: Ninguna configuraci√≥n de {nombre} est√° por debajo de {max_precision*100}%")
            print(f"Usando la configuraci√≥n con menor precisi√≥n disponible")
            best_idx = np.argmin(results['mean_test_score'])
        else:
            # Ordenar por precisi√≥n y tomar el mejor
            valid_scores = [(results['mean_test_score'][i], i) for i in valid_indices]
            valid_scores.sort(reverse=True)
            best_idx = valid_scores[0][1]
        
        # Obtener los par√°metros del mejor modelo v√°lido
        best_params = results['params'][best_idx]
        best_cv_score = results['mean_test_score'][best_idx]
        
        # Crear y entrenar el modelo con esos par√°metros
        if nombre == "KNN":
            best_model = KNeighborsClassifier(**best_params)
        elif nombre == "Random Forest":
            best_model = RandomForestClassifier(**best_params, random_state=42)
        
        best_model.fit(X_train, y_train)
        
        print(f"Mejor {nombre} (restringido): {best_params}")
        print(f"Precisi√≥n CV: {best_cv_score:.4f}")
        
        return best_model, best_params, best_cv_score
    
    else:
        # Para regresi√≥n log√≠stica, usar el comportamiento original
        return modelo_grid.best_estimator_, modelo_grid.best_params_, modelo_grid.best_score_

# KNN con restricci√≥n de precisi√≥n m√°xima del 96%
knn_params = {'n_neighbors': list(range(1, 10))}        # Define una grilla de valores de vecinos (de 1 a 9) para probar en el clasificador KNN
knn_model = GridSearchCV(KNeighborsClassifier(), knn_params, cv=30)  # Crea un GridSearchCV para buscar el mejor n√∫mero de vecinos usando validaci√≥n cruzada
knn_model.fit(X_train, y_train)                         # Entrena el modelo KNN con los mejores hiperpar√°metros

# Obtener el mejor modelo KNN que no supere 96%
knn_best, knn_best_params, knn_best_cv_score = obtener_mejor_modelo_restringido(knn_model, "KNN", X_train, y_train, max_precision=0.96)
knn_pred = knn_best.predict(X_test)                     # Predice las clases del conjunto de prueba usando el mejor modelo KNN
knn_proba = knn_best.predict_proba(X_test)[:, 1]        # Calcula las probabilidades predichas de la clase positiva (1)

# Random Forest con restricci√≥n de precisi√≥n m√°xima del 96%
rf_params = {'max_depth': list(range(1, 10))}           # Define una grilla de valores para la profundidad m√°xima del √°rbol (1 a 9)
rf_model = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=30)  # Crea un GridSearchCV para ajustar el clasificador Random Forest buscando la mejor profundidad
rf_model.fit(X_train, y_train)                          # Entrena el modelo Random Forest con los mejores hiperpar√°metros

# Obtener el mejor modelo Random Forest que no supere 96%
rf_best, rf_best_params, rf_best_cv_score = obtener_mejor_modelo_restringido(rf_model, "Random Forest", X_train, y_train, max_precision=0.96)
rf_pred = rf_best.predict(X_test)                       # Predice las clases del conjunto de prueba con el mejor modelo
rf_proba = rf_best.predict_proba(X_test)[:, 1]          # Calcula las probabilidades de la clase positiva (1) para m√©tricas de evaluaci√≥n

# 7. Evaluar m√∫ltiples configuraciones con restricci√≥n de precisi√≥n
def top_n_modelos_restringido(modelo_grid, nombre, X_train, y_train, X_test, y_test, n=4, max_precision=0.96):
    results = modelo_grid.cv_results_                   # Obtiene todos los resultados de la validaci√≥n cruzada del GridSearchCV
    
    # Filtrar configuraciones que no superen la precisi√≥n m√°xima
    if nombre in ["KNN", "Random Forest"]:
        valid_indices = [i for i, score in enumerate(results['mean_test_score']) if score <= max_precision]
        if len(valid_indices) < n:
            print(f"‚ö†Ô∏è  Advertencia: Solo {len(valid_indices)} configuraciones de {nombre} no superan {max_precision*100}% de precisi√≥n")
            valid_indices = valid_indices if valid_indices else list(range(len(results['mean_test_score'])))
        
        # Ordenar por precisi√≥n y tomar los mejores n
        valid_scores = [(results['mean_test_score'][i], i) for i in valid_indices]
        valid_scores.sort(reverse=True)
        sorted_indices = [idx for _, idx in valid_scores[:n]]
    else:
        # Para regresi√≥n log√≠stica, usar el comportamiento original
        sorted_indices = np.argsort(results['rank_test_score'])[:n]
    
    print(f"\n\n Top {min(len(sorted_indices), n)} resultados para {nombre} (m√°x. {max_precision*100}% precisi√≥n):")

    for rank, idx in enumerate(sorted_indices, start=1):  # Itera sobre los mejores modelos, obteniendo su posici√≥n (rank) e √≠ndice original en el array
        params = results['params'][idx]                 # Extrae los hiperpar√°metros de ese modelo espec√≠fico
        cv_precision = results['mean_test_score'][idx]  # Obtiene la precisi√≥n de validaci√≥n cruzada

        # Seg√∫n el nombre del modelo, instancia el clasificador con esos hiperpar√°metros
        if nombre == "Regresi√≥n Log√≠stica":
            modelo = LogisticRegression(**params, random_state=42)
        elif nombre == "KNN":
            modelo = KNeighborsClassifier(**params)
        elif nombre == "Random Forest":
            modelo = RandomForestClassifier(**params, random_state=42)
        else:
            continue                                    # Si el nombre no coincide, salta esa iteraci√≥n

        modelo.fit(X_train, y_train)                    # Entrena el modelo con los datos de entrenamiento

        y_pred = modelo.predict(X_test)                 # Predice las clases con el conjunto de prueba
        y_proba = modelo.predict_proba(X_test)[:, 1]    # Predice las probabilidades de la clase positiva (1)

        print(f"\n--- {nombre} (Top #{rank}) ---")      # Muestra qu√© configuraci√≥n se est√° evaluando
        print("Configuraci√≥n:", params)                 # Muestra los hiperpar√°metros usados
        print(f"Precisi√≥n CV: {cv_precision:.4f}")      # Muestra la precisi√≥n de validaci√≥n cruzada
        print("Matriz de confusi√≥n:\n", confusion_matrix(y_test, y_pred))  # Imprime la matriz de confusi√≥n entre predicciones y etiquetas reales
        print("Reporte de clasificaci√≥n:\n", classification_report(y_test, y_pred))  # Imprime m√©tricas como precisi√≥n, recall y f1-score para cada clase
        print("Precisi√≥n test:", accuracy_score(y_test, y_pred))  # Muestra la precisi√≥n (accuracy) del modelo en test
        print("AUC:", roc_auc_score(y_test, y_proba))   # Calcula y muestra el AUC (√°rea bajo la curva ROC)

# Evaluar los mejores resultados de cada modelo con restricci√≥n
top_n_modelos_restringido(log_model, "Regresi√≥n Log√≠stica", X_train, y_train, X_test, y_test, n=4)  # Regresi√≥n log√≠stica sin restricci√≥n
top_n_modelos_restringido(knn_model, "KNN", X_train, y_train, X_test, y_test, n=4, max_precision=0.96)  # KNN con restricci√≥n del 96%
top_n_modelos_restringido(rf_model, "Random Forest", X_train, y_train, X_test, y_test, n=4, max_precision=0.96)  # Random Forest con restricci√≥n del 96%

# Ahora los modelos knn_best y rf_best ya respetan la restricci√≥n del 96%
log_proba_0 = log_best.predict_proba(X_test)[:, 0]
knn_proba_0 = knn_best.predict_proba(X_test)[:, 0]
rf_proba_0 = rf_best.predict_proba(X_test)[:, 0]

# Invertimos las etiquetas: ahora la clase "0" es la positiva
y_test_invertido = 1 - y_test

# 8. Graficar curvas ROC para la clase 0 (usando modelos con restricci√≥n aplicada)
plt.figure(figsize=(8, 6))  # Crea una figura nueva con tama√±o 8x6 pulgadas
# Itera sobre cada modelo junto con sus probabilidades de clase positiva (y_proba)
for nombre, y_proba in zip(["Logistic Regression", "KNN", "Random Forest"], [log_proba_0, knn_proba_0, rf_proba_0]):  

    fpr, tpr, _ = roc_curve(y_test_invertido, y_proba)  # Calcula los valores de FPR (False Positive Rate) y TPR (True Positive Rate) para la curva ROC
    plt.plot(fpr, tpr, label=f'{nombre} (AUC: {int(roc_auc_score(y_test_invertido, y_proba) * 100) / 100:.2f})')

plt.plot([0, 1], [0, 1], 'k--')  # Dibuja una l√≠nea diagonal como referencia (clasificador aleatorio)
plt.xlabel('FPR (Clase 0)')  # Etiqueta para el eje X: Tasa de Falsos Positivos
plt.ylabel('TPR (Clase 0)')  # Etiqueta para el eje Y: Tasa de Verdaderos Positivos
plt.title('Curvas ROC [Clase 0]')  # T√≠tulo del gr√°fico
plt.legend()  # Muestra la leyenda con los nombres de los modelos y sus AUC
plt.grid(True)  # Agrega una cuadr√≠cula al gr√°fico
plt.tight_layout()  # Ajusta el dise√±o para evitar que se superpongan elementos
plt.show()  # Muestra el gr√°fico en pantalla

# 8.1. Graficar curvas ROC para la clase 1 (usando modelos con restricci√≥n aplicada)
plt.figure(figsize=(8, 6))  # Crea una figura nueva con tama√±o 8x6 pulgadas
# Itera sobre cada modelo junto con sus probabilidades de clase positiva (y_proba)
for nombre, y_proba in zip(["Logistic Regression", "KNN", "Random Forest"], [log_proba, knn_proba, rf_proba]):  

    fpr, tpr, _ = roc_curve(y_test, y_proba)  # Calcula los valores de FPR (False Positive Rate) y TPR (True Positive Rate) para la curva ROC
    plt.plot(fpr, tpr, label=f'{nombre} (AUC: {int(roc_auc_score(y_test, y_proba) * 100) / 100:.2f})')

plt.plot([0, 1], [0, 1], 'k--')  # Dibuja una l√≠nea diagonal como referencia (clasificador aleatorio)
plt.xlabel('FPR (Clase 1)')  # Etiqueta para el eje X: Tasa de Falsos Positivos
plt.ylabel('TPR (Clase 1)')  # Etiqueta para el eje Y: Tasa de Verdaderos Positivos
plt.title('Curvas ROC [Clase 1]')  # T√≠tulo del gr√°fico
plt.legend()  # Muestra la leyenda con los nombres de los modelos y sus AUC
plt.grid(True)  # Agrega una cuadr√≠cula al gr√°fico
plt.tight_layout()  # Ajusta el dise√±o para evitar que se superpongan elementos
plt.show()  # Muestra el gr√°fico en pantalla

# 8.2 Curvas ROC para discriminar entre clases de los mejores modelos encontrados (KNN con restricci√≥n)
# Calcular curvas ROC
fpr_knn, tpr_knn, _ = roc_curve(y_test, knn_proba)
roc_auc_knn = auc(fpr_knn, tpr_knn)

fpr_knn_0, tpr_knn_0, _ = roc_curve(y_test_invertido, knn_proba_0)
roc_auc_knn_0 = auc(fpr_knn_0, tpr_knn_0)

# Plot
plt.figure(figsize=(8, 6))
plt.plot(fpr_knn, tpr_knn, label=f'Clase 1 (AUC = {roc_auc_knn:.2f})')
plt.plot(fpr_knn_0, tpr_knn_0, label=f'Clase 0 (AUC = {roc_auc_knn_0:.2f})')

# Diagonal
plt.plot([0, 1], [0, 1], 'k--')

plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title(f'Curvas ROC del mejor modelo KNN (Restricci√≥n 96%) - {knn_best_params}')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

# 8.3 Curvas ROC para discriminar entre clases de los mejores modelos encontrados (Random Forest con restricci√≥n)
# Calcular curvas ROC
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_proba)
roc_auc_rf = auc(fpr_rf, tpr_rf)

fpr_rf_0, tpr_rf_0, _ = roc_curve(y_test_invertido, rf_proba_0)
roc_auc_rf_0 = auc(fpr_rf_0, tpr_rf_0)

# Plot
plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, label=f'Clase 1 (AUC = {roc_auc_rf:.2f})')
plt.plot(fpr_rf_0, tpr_rf_0, label=f'Clase 0 (AUC = {roc_auc_rf_0:.2f})')

# Diagonal
plt.plot([0, 1], [0, 1], 'k--')

plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title(f'Curvas ROC del mejor modelo Random Forest (Restricci√≥n 96%) - {rf_best_params}')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

# 8.4 Curvas ROC para discriminar entre clases de los mejores modelos encontrados (Regresi√≥n logistica)
# Calcular curvas ROC
fpr_log, tpr_log, _ = roc_curve(y_test, log_proba)
roc_auc_log = auc(fpr_log, tpr_log)

fpr_log_0, tpr_log_0, _ = roc_curve(y_test_invertido, log_proba_0)
roc_auc_log_0 = auc(fpr_log_0, tpr_log_0)

# Plot
plt.figure(figsize=(8, 6))
plt.plot(fpr_log, tpr_log, label=f'Clase 1 (AUC = {roc_auc_log:.2f})')
plt.plot(fpr_log_0, tpr_log_0, label=f'Clase 0 (AUC = {roc_auc_log_0:.2f})')

# Diagonal
plt.plot([0, 1], [0, 1], 'k--')

plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title('Curvas ROC del mejor modelo Regresi√≥n Log√≠stica')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

# 9. Matrices de confusi√≥n heatmap (usando modelos con restricci√≥n aplicada)
# Crea una lista de tuplas con el nombre del modelo y sus predicciones en el test set
modelos = [("Logistic Regression", log_pred), ("KNN (‚â§96%)", knn_pred), ("Random Forest (‚â§96%)", rf_pred)]
for nombre, pred in modelos: # Itera sobre cada modelo y sus predicciones
    plt.figure() # Crea una nueva figura para cada heatmap
    # Dibuja un mapa de calor de la matriz de confusi√≥n con anotaciones, usando el esquema de colores 'Blues'
    sns.heatmap(confusion_matrix(y_test, pred), annot=True, fmt='d', cmap='Blues')
    plt.title(f'Matriz de Confusi√≥n - {nombre}') # T√≠tulo con el nombre del modelo
    plt.xlabel('Predicci√≥n') # Etiqueta del eje X
    plt.ylabel('Real') # Etiqueta del eje Y
    plt.tight_layout() # Ajusta autom√°ticamente los m√°rgenes para evitar solapamientos
    plt.show() # Muestra el gr√°fico

# 10. Curvas de precisi√≥n vs hiperpar√°metros (con restricci√≥n aplicada)
# KNN - Mostrar solo configuraciones que no superen 96%
plt.figure()
knn_scores = knn_model.cv_results_['mean_test_score']
knn_params_values = knn_params['n_neighbors']
# Filtrar valores que no superen 96%
knn_filtered_scores = []
knn_filtered_params = []
for i, (param, score) in enumerate(zip(knn_params_values, knn_scores)):
    if score <= 0.96:
        knn_filtered_params.append(param)
        knn_filtered_scores.append(score)

plt.plot(knn_filtered_params, knn_filtered_scores, marker='o', label='‚â§96% precisi√≥n')
plt.plot(knn_params_values, knn_scores, marker='x', alpha=0.5, label='Todos los valores')
# Marcar el mejor modelo seleccionado
if knn_best_params['n_neighbors'] in knn_filtered_params:
    best_score = knn_scores[knn_params_values.index(knn_best_params['n_neighbors'])]
    plt.plot(knn_best_params['n_neighbors'], best_score, marker='*', markersize=15, color='red', label=f'Mejor seleccionado (k={knn_best_params["n_neighbors"]})')
plt.title("Precisi√≥n KNN vs K (con restricci√≥n 96%)")
plt.xlabel("Valores de K")
plt.ylabel("Precisi√≥n")
plt.axhline(y=0.96, color='r', linestyle='--', label='L√≠mite 96%')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Random Forest - Mostrar solo configuraciones que no superen 96%
plt.figure()
rf_scores = rf_model.cv_results_['mean_test_score']
rf_params_values = rf_params['max_depth']
# Filtrar valores que no superen 96%
rf_filtered_scores = []
rf_filtered_params = []
for i, (param, score) in enumerate(zip(rf_params_values, rf_scores)):
    if score <= 0.96:
        rf_filtered_params.append(param)
        rf_filtered_scores.append(score)

plt.plot(rf_filtered_params, rf_filtered_scores, marker='o', color='green', label='‚â§96% precisi√≥n')
plt.plot(rf_params_values, rf_scores, marker='x', color='green', alpha=0.5, label='Todos los valores')
# Marcar el mejor modelo seleccionado
if rf_best_params['max_depth'] in rf_filtered_params:
    best_score = rf_scores[rf_params_values.index(rf_best_params['max_depth'])]
    plt.plot(rf_best_params['max_depth'], best_score, marker='*', markersize=15, color='red', label=f'Mejor seleccionado (depth={rf_best_params["max_depth"]})')
plt.title("Precisi√≥n RF vs Max Depth (con restricci√≥n 96%)")
plt.xlabel("Profundidad m√°xima")
plt.ylabel("Precisi√≥n")
plt.axhline(y=0.96, color='r', linestyle='--', label='L√≠mite 96%')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Regresi√≥n Log√≠stica (sin restricci√≥n)
accuracies_test = []
for c in log_params['C']:
    model = LogisticRegression(C=c, max_iter=1000)
    model.fit(X_train, y_train)
    acc = accuracy_score(y_test, model.predict(X_test))
    accuracies_test.append(acc)

plt.figure()
plt.plot(log_params['C'], accuracies_test, marker='o', color='red')
plt.xscale('log')
plt.title("Precisi√≥n Regresi√≥n Log√≠stica vs C")
plt.xlabel("Valores de C (log)")
plt.ylabel("Precisi√≥n")
plt.grid(True)
plt.tight_layout()
plt.show()

# 11. Guardar mejor modelo y scaler (ahora rf_best respeta la restricci√≥n del 96%)
joblib.dump(rf_best, 'rf_model.pkl')  # Guarda el mejor modelo de Random Forest en un archivo .pkl
joblib.dump(scaler, 'scaler.pkl')     # Guarda el escalador est√°ndar para uso posterior (ej. predicciones nuevas)

print(f"\n‚úÖ Modelo Random Forest guardado con restricci√≥n 96%:")
print(f"Par√°metros: {rf_best_params}")
print(f"Precisi√≥n CV: {rf_best_cv_score:.4f}")
print(f"Precisi√≥n Test: {accuracy_score(y_test, rf_pred):.4f}")

# 12. Predicci√≥n interactiva
def entrada_usuario():
    print("\nüîé Por favor, responde las siguientes preguntas:")

    preguntas = {
        "age": "Edad (a√±os): ",
        "sex": "Sexo (1: Hombre, 0: Mujer): ",
        "cp": "Tipo de dolor en el pecho (0-3): ",
        "trestbps": "Presi√≥n arterial en reposo (mm Hg): ",
        "chol": "Colesterol s√©rico (mg/dl): ",
        "fbs": "Az√∫car en sangre en ayunas > 120 mg/dl (1: S√≠, 0: No): ",
        "restecg": "Resultados del ECG en reposo (0-2): ",
        "thalach": "Frecuencia card√≠aca m√°xima alcanzada: ",
        "exang": "Angina inducida por ejercicio (1: S√≠, 0: No): ",
        "oldpeak": "Depresi√≥n ST inducida por el ejercicio: ",
        "slope": "Pendiente del segmento ST (0-2): ",
        "ca": "N¬∫ de vasos principales coloreados (0-3): ",
        "thal": "Resultado del test Thal (1 = normal; 2 = fijo; 3 = reversible): "
    }

    # Inicializa una lista vac√≠a donde se guardar√°n los valores ingresados por el usuario
    valores = []
    for var, pregunta in preguntas.items(): # Itera sobre el diccionario 'preguntas', donde la clave es el nombre de la variable y el valor es el texto de la pregunta
        valor = float(input(pregunta)) # Muestra la pregunta al usuario y convierte la respuesta a float (valor num√©rico)
        valores.append(valor) # Agrega el valor ingresado a la lista 'valores'

    entrada_np = np.array(valores).reshape(1, -1) # Convierte la lista a un arreglo NumPy y lo redimensiona a una matriz de una fila (1 muestra, n columnas)
    scaler = joblib.load('scaler.pkl') # Carga el objeto de escalado previamente guardado (StandardScaler)
    modelo = joblib.load('rf_model.pkl') # Carga el modelo Random Forest entrenado y guardado previamente

    entrada_scaled = scaler.transform(entrada_np) # Escala la entrada del usuario con el mismo escalador usado durante el entrenamiento
    # Calcula la probabilidad de que la entrada pertenezca a la clase positiva (clase 1)
    # `predict_proba` devuelve una matriz con dos columnas: [proba_clase_0, proba_clase_1]
    # Por eso se accede con `[0][1]` para obtener la probabilidad de clase 1 de la primera (y √∫nica) muestra
    proba = modelo.predict_proba(entrada_scaled)[0][1]

    # Si la prob es mayor a 0.6 hay riesgo de enfermedad cardiaca
    if proba > 0.6:
        print("\nüî¥ Riesgo alto de enfermedad card√≠aca.")
    else: # en caso contrario la persona estara sana
        print("\nüü¢ Bajo riesgo de enfermedad card√≠aca.")

# Descomentar para usar en consola
# entrada_usuario()

# =============================================================================
# AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS
# =============================================================================

print("\n" + "="*60)
print("üìä AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS")
print("="*60)

# Obtener los nombres de las caracter√≠sticas
feature_names = X.columns.tolist()

# 1. IMPORTANCIA BASADA EN RANDOM FOREST (Feature Importance)
print("\n1Ô∏è‚É£ IMPORTANCIA BASADA EN RANDOM FOREST:")
print("-" * 50)

# Obtener importancias del mejor modelo Random Forest
rf_importances = rf_best.feature_importances_
rf_importance_df = pd.DataFrame({
    'Caracter√≠stica': feature_names,
    'Importancia': rf_importances,
    'Porcentaje': rf_importances * 100
}).sort_values('Importancia', ascending=False)

print("Ranking de importancia (Random Forest):")
for i, row in rf_importance_df.iterrows():
    print(f"{row.name+1:2d}. {row['Caracter√≠stica']:12s} - {row['Porcentaje']:5.2f}%")

# Visualizar importancias de Random Forest
plt.figure(figsize=(10, 6))
plt.barh(range(len(rf_importance_df)), rf_importance_df['Porcentaje'])
plt.yticks(range(len(rf_importance_df)), rf_importance_df['Caracter√≠stica'])
plt.xlabel('Importancia (%)')
plt.title('Importancia de Caracter√≠sticas - Random Forest')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# 2. IMPORTANCIA POR PERMUTACI√ìN (m√°s robusta)
print("\n2Ô∏è‚É£ IMPORTANCIA POR PERMUTACI√ìN:")
print("-" * 50)

# Calcular importancia por permutaci√≥n para Random Forest
perm_importance = permutation_importance(rf_best, X_test, y_test, 
                                       n_repeats=10, random_state=42, 
                                       scoring='accuracy')

perm_importance_df = pd.DataFrame({
    'Caracter√≠stica': feature_names,
    'Importancia_Media': perm_importance.importances_mean,
    'Desviaci√≥n_Std': perm_importance.importances_std,
    'Porcentaje': perm_importance.importances_mean * 100
}).sort_values('Importancia_Media', ascending=False)

print("Ranking de importancia (Permutaci√≥n):")
for i, row in perm_importance_df.iterrows():
    print(f"{row.name+1:2d}. {row['Caracter√≠stica']:12s} - {row['Porcentaje']:5.2f}% (¬±{row['Desviaci√≥n_Std']*100:.2f}%)")

# Visualizar importancias por permutaci√≥n
plt.figure(figsize=(10, 6))
plt.barh(range(len(perm_importance_df)), perm_importance_df['Porcentaje'])
plt.yticks(range(len(perm_importance_df)), perm_importance_df['Caracter√≠stica'])
plt.xlabel('Importancia (%)')
plt.title('Importancia de Caracter√≠sticas - Permutaci√≥n')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# 3. AN√ÅLISIS ESTAD√çSTICO UNIVARIADO (F-Score)
print("\n3Ô∏è‚É£ AN√ÅLISIS ESTAD√çSTICO (F-Score):")
print("-" * 50)

# Calcular F-scores
selector = SelectKBest(score_func=f_classif, k='all')
selector.fit(X_scaled, y)

f_scores = selector.scores_
f_scores_df = pd.DataFrame({
    'Caracter√≠stica': feature_names,
    'F_Score': f_scores,
    'Porcentaje': (f_scores / f_scores.sum()) * 100
}).sort_values('F_Score', ascending=False)

print("Ranking de F-Score:")
for i, row in f_scores_df.iterrows():
    print(f"{row.name+1:2d}. {row['Caracter√≠stica']:12s} - F-Score: {row['F_Score']:6.2f} ({row['Porcentaje']:5.2f}%)")

# 4. SELECCI√ìN RECURSIVA DE CARACTER√çSTICAS (RFE)
print("\n4Ô∏è‚É£ SELECCI√ìN RECURSIVA DE CARACTER√çSTICAS (RFE):")
print("-" * 50)

# Usar RFE con Random Forest
rfe = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=8)
rfe.fit(X_scaled, y)

rfe_ranking_df = pd.DataFrame({
    'Caracter√≠stica': feature_names,
    'Ranking_RFE': rfe.ranking_,
    'Seleccionado': rfe.support_
}).sort_values('Ranking_RFE')

print("Ranking RFE (1 = m√°s importante):")
for i, row in rfe_ranking_df.iterrows():
    status = "‚úÖ SELECCIONADO" if row['Seleccionado'] else "‚ùå ELIMINADO"
    print(f"{row['Ranking_RFE']:2d}. {row['Caracter√≠stica']:12s} - {status}")

# 5. COMPARACI√ìN CONSOLIDADA
print("\n5Ô∏è‚É£ COMPARACI√ìN CONSOLIDADA:")
print("-" * 50)

# Crear ranking promedio
comparison_df = pd.DataFrame({
    'Caracter√≠stica': feature_names,
    'RF_Rank': rf_importance_df.reset_index()['Caracter√≠stica'].apply(lambda x: rf_importance_df[rf_importance_df['Caracter√≠stica'] == x].index[0] + 1).values,
    'Perm_Rank': perm_importance_df.reset_index()['Caracter√≠stica'].apply(lambda x: perm_importance_df[perm_importance_df['Caracter√≠stica'] == x].index[0] + 1).values,
    'F_Rank': f_scores_df.reset_index()['Caracter√≠stica'].apply(lambda x: f_scores_df[f_scores_df['Caracter√≠stica'] == x].index[0] + 1).values,
    'RFE_Rank': [rfe_ranking_df[rfe_ranking_df['Caracter√≠stica'] == feat]['Ranking_RFE'].values[0] for feat in feature_names]
})

# Calcular ranking promedio
comparison_df['Ranking_Promedio'] = comparison_df[['RF_Rank', 'Perm_Rank', 'F_Rank', 'RFE_Rank']].mean(axis=1)
comparison_df = comparison_df.sort_values('Ranking_Promedio')

print("Ranking consolidado (promedio de todos los m√©todos):")
for i, row in comparison_df.iterrows():
    print(f"{i+1:2d}. {row['Caracter√≠stica']:12s} - Promedio: {row['Ranking_Promedio']:4.1f} "
          f"(RF:{row['RF_Rank']:2d}, Perm:{row['Perm_Rank']:2d}, F:{row['F_Rank']:2d}, RFE:{row['RFE_Rank']:2d})")

# 6. AN√ÅLISIS DE CARACTER√çSTICAS MENOS IMPORTANTES
print("\n6Ô∏è‚É£ AN√ÅLISIS DE CARACTER√çSTICAS POTENCIALMENTE ELIMINABLES:")
print("-" * 50)

# Caracter√≠sticas que consistentemente rankean bajo
umbral_ranking = len(feature_names) * 0.7  # 70% hacia abajo

caracteristicas_bajas = comparison_df[comparison_df['Ranking_Promedio'] > umbral_ranking]

if len(caracteristicas_bajas) > 0:
    print("Caracter√≠sticas con menor importancia consistente:")
    for i, row in caracteristicas_bajas.iterrows():
        print(f"‚ö†Ô∏è  {row['Caracter√≠stica']:12s} - Ranking promedio: {row['Ranking_Promedio']:4.1f}")
    
    # Probar rendimiento sin estas caracter√≠sticas
    print(f"\nüß™ PRUEBA SIN LAS {len(caracteristicas_bajas)} CARACTER√çSTICAS MENOS IMPORTANTES:")
    
    # Obtener √≠ndices de caracter√≠sticas a mantener
    caracteristicas_importantes = comparison_df[comparison_df['Ranking_Promedio'] <= umbral_ranking]['Caracter√≠stica'].tolist()
    indices_importantes = [feature_names.index(feat) for feat in caracteristicas_importantes]
    
    # Entrenar modelo solo con caracter√≠sticas importantes
    X_reduced = X_scaled[:, indices_importantes]
    X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(
        X_reduced, y, test_size=0.2, random_state=42, stratify=y)
    
    rf_reduced = RandomForestClassifier(**rf_best_params, random_state=42)
    rf_reduced.fit(X_train_red, y_train_red)
    
    # Evaluar rendimiento
    y_pred_reduced = rf_reduced.predict(X_test_red)
    accuracy_reduced = accuracy_score(y_test_red, y_pred_reduced)
    accuracy_original = accuracy_score(y_test, rf_pred)
    
    print(f"Precisi√≥n con todas las caracter√≠sticas: {accuracy_original:.4f}")
    print(f"Precisi√≥n con {len(caracteristicas_importantes)} caracter√≠sticas: {accuracy_reduced:.4f}")
    print(f"Diferencia: {accuracy_reduced - accuracy_original:+.4f}")
    
    if accuracy_reduced >= accuracy_original - 0.01:  # Tolerancia del 1%
        print("‚úÖ Las caracter√≠sticas eliminadas NO son indispensables")
        print(f"Caracter√≠sticas suficientes: {caracteristicas_importantes}")
    else:
        print("‚ùå Todas las caracter√≠sticas parecen ser importantes")
else:
    print("‚úÖ Todas las caracter√≠sticas muestran importancia significativa")

# 7. HEATMAP DE CORRELACI√ìN CON IMPORTANCIAS
print("\n7Ô∏è‚É£ MAPA DE CALOR - CORRELACIONES E IMPORTANCIAS:")
print("-" * 50)

# Crear correlaci√≥n con target
correlations = X.corrwith(y).abs().sort_values(ascending=False)
correlation_df = pd.DataFrame({
    'Caracter√≠stica': correlations.index,
    'Correlaci√≥n_Abs': correlations.values,
    'Porcentaje_Corr': (correlations.values / correlations.sum()) * 100
})

plt.figure(figsize=(12, 8))
# Matriz de correlaci√≥n
correlation_matrix = X.corr()
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
            square=True, fmt='.2f', cbar_kws={'label': 'Correlaci√≥n'})
plt.title('Matriz de Correlaci√≥n entre Caracter√≠sticas')
plt.tight_layout()
plt.show()

# Mostrar correlaciones con target
print("Correlaci√≥n absoluta con variable objetivo:")
for i, row in correlation_df.iterrows():
    print(f"{i+1:2d}. {row['Caracter√≠stica']:12s} - {row['Correlaci√≥n_Abs']:.3f} ({row['Porcentaje_Corr']:5.2f}%)")

print("\n" + "="*60)
print("‚úÖ AN√ÅLISIS COMPLETADO")
print("="*60)