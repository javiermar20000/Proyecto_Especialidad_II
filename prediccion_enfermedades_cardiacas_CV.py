import pandas as pd                         # Importa la biblioteca pandas para manipulaci√≥n y an√°lisis de datos (estructuras tipo DataFrame).
import numpy as np                          # Importa la biblioteca NumPy para operaciones num√©ricas y manejo de arrays.
import joblib                               # Importa joblib para guardar y cargar modelos entrenados u otros objetos de Python.
import matplotlib.pyplot as plt             # Importa matplotlib para generar gr√°ficos y visualizaciones.
import seaborn as sns                       # Importa seaborn para visualizaciones estad√≠sticas m√°s est√©ticas y avanzadas.
import warnings                             # Importa el m√≥dulo warnings para controlar la aparici√≥n de advertencias.
from sklearn.model_selection import train_test_split, GridSearchCV    # Importa funciones para dividir datos y hacer b√∫squeda de hiperpar√°metros.
from sklearn.ensemble import RandomForestClassifier                   # Importa el clasificador de bosque aleatorio (Random Forest).
from sklearn.linear_model import LogisticRegression                   # Importa el modelo de regresi√≥n log√≠stica.
from sklearn.neighbors import KNeighborsClassifier                    # Importa el clasificador basado en vecinos m√°s cercanos (KNN).
from sklearn.metrics import (                                         # Importa m√©tricas para evaluar modelos de clasificaci√≥n:
    classification_report,                                            # - Reporte con precisi√≥n, recall, f1-score, etc.
    confusion_matrix,                                                 # - Matriz de confusi√≥n para ver aciertos y errores por clase.
    accuracy_score,                                                   # - Porcentaje de aciertos totales.
    roc_auc_score,                                                    # - √Årea bajo la curva ROC.
    roc_curve,                                                        # - Puntos para trazar la curva ROC.
    auc                                                               # - C√°lculo del √°rea bajo cualquier curva dada (como la ROC).
)
from sklearn.preprocessing import StandardScaler                      # Importa el escalador est√°ndar para normalizar los datos.
warnings.filterwarnings("ignore")                                     # Desactiva las advertencias para evitar que se muestren en la salida del programa.

# =============================================================================
# CARGA Y PREPARACI√ìN DE DATOS
# =============================================================================

# 1. Cargar el dataset
df = pd.read_csv('heart_attack_desease.csv')                         # Carga el archivo CSV con los datos sobre enfermedades card√≠acas en un DataFrame.

# 2. Revisar valores nulos
print("Valores nulos por columna:\n", df.isnull().sum())            # Muestra cu√°ntos valores nulos hay por columna para detectar datos faltantes.

# 3. Separar caracter√≠sticas (X) y etiqueta (y)
X = df.drop('target', axis=1)                                        # Separa las caracter√≠sticas del modelo, eliminando la columna 'target'.
y = df['target']                                                     # Asigna la columna 'target' como variable objetivo (etiqueta a predecir).

# 4. Escalar los datos
scaler = StandardScaler()                                            # Crea un objeto escalador que normaliza los datos (media 0, desviaci√≥n est√°ndar 1).
X_scaled = scaler.fit_transform(X)                                   # Ajusta el escalador a los datos y transforma las caracter√≠sticas escal√°ndolas.

# 5. Dividir en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(                 # Divide los datos en conjunto de entrenamiento y prueba:
    X_scaled, y, test_size=0.2, random_state=42, stratify=y)         # - 80% para entrenamiento, 20% para prueba, con distribuci√≥n balanceada seg√∫n 'y'.

# =============================================================================
# FUNCIONES AUXILIARES
# =============================================================================

# Obtiene el mejor modelo que no supere la precisi√≥n m√°xima especificada
def obtener_mejor_modelo_restringido(modelo_grid, nombre, X_train, y_train, max_precision=0.96):  # Define una funci√≥n que selecciona el mejor modelo limitado por una precisi√≥n m√°xima.
    results = modelo_grid.cv_results_                                                              # Obtiene todos los resultados de validaci√≥n cruzada del GridSearchCV.

    if nombre in ["KNN", "Random Forest"]:                                                         # Solo aplica esta l√≥gica personalizada si el modelo es KNN o Random Forest.
        # Filtrar configuraciones que no superen la precisi√≥n m√°xima
        valid_indices = [i for i, score in enumerate(results['mean_test_score']) if score <= max_precision]  # Guarda los √≠ndices de las configuraciones que cumplen con la restricci√≥n de precisi√≥n.

        if len(valid_indices) == 0:                                                                # Si no hay configuraciones v√°lidas (todas superan el l√≠mite de precisi√≥n)...
            print(f"Advertencia: Ninguna configuraci√≥n de {nombre} est√° por debajo de {max_precision*100}%")  # ...muestra advertencia...
            print(f"Usando la configuraci√≥n con menor precisi√≥n disponible")                       # ...e informa que se usar√° la menos precisa.
            best_idx = np.argmin(results['mean_test_score'])                                       # Toma el √≠ndice del modelo con menor precisi√≥n (por si acaso hay sobreajuste extremo).
        else:
            # Ordenar por precisi√≥n y tomar el mejor
            valid_scores = [(results['mean_test_score'][i], i) for i in valid_indices]             # Crea lista de tuplas (precisi√≥n, √≠ndice) para configuraciones v√°lidas.
            valid_scores.sort(reverse=True)                                                        # Ordena las tuplas de mayor a menor precisi√≥n.
            best_idx = valid_scores[0][1]                                                           # Toma el √≠ndice de la mejor configuraci√≥n dentro del l√≠mite permitido.

        # Obtener los par√°metros del mejor modelo v√°lido
        best_params = results['params'][best_idx]                                                  # Extrae los par√°metros del mejor modelo.
        best_cv_score = results['mean_test_score'][best_idx]                                       # Extrae la precisi√≥n de validaci√≥n cruzada del mejor modelo.

        # Crear y entrenar el modelo con esos par√°metros
        if nombre == "KNN":
            best_model = KNeighborsClassifier(**best_params)                                       # Si es KNN, crea un modelo con los mejores par√°metros encontrados.
        elif nombre == "Random Forest":
            best_model = RandomForestClassifier(**best_params, random_state=42)                    # Si es Random Forest, crea el modelo con los mejores par√°metros y semilla fija.

        best_model.fit(X_train, y_train)                                                            # Entrena el modelo seleccionado con los datos de entrenamiento.

        print(f"Mejor {nombre} (restringido): {best_params}")                                      # Muestra los par√°metros del mejor modelo restringido.
        print(f"Precisi√≥n CV: {best_cv_score:.4f}")                                                # Muestra la precisi√≥n obtenida en validaci√≥n cruzada.

        return best_model, best_params, best_cv_score                                              # Retorna el modelo entrenado, sus par√°metros y su precisi√≥n de validaci√≥n.

    else:
        # Para regresi√≥n log√≠stica, usar el comportamiento original
        return modelo_grid.best_estimator_, modelo_grid.best_params_, modelo_grid.best_score_      # Si no es KNN ni Random Forest, retorna el mejor modelo como lo entrega GridSearchCV.

# Eval√∫a y muestra los mejores n modelos con restricci√≥n de precisi√≥n
def top_n_modelos_restringido(modelo_grid, nombre, X_train, y_train, X_test, y_test, n=4, max_precision=0.96):  # Define una funci√≥n para mostrar los top n modelos con precisi√≥n ‚â§ max_precision.
    results = modelo_grid.cv_results_                                              # Extrae todos los resultados de validaci√≥n cruzada del GridSearchCV.

    # Filtrar configuraciones que no superen la precisi√≥n m√°xima
    if nombre in ["KNN", "Random Forest"]:                                         # Solo aplica la l√≥gica de restricci√≥n si el modelo es KNN o Random Forest.
        valid_indices = [i for i, score in enumerate(results['mean_test_score']) if score <= max_precision]  # Filtra √≠ndices con precisi√≥n menor o igual al l√≠mite.

        if len(valid_indices) < n:                                                 # Si hay menos modelos v√°lidos que n...
            print(f"Advertencia: Solo {len(valid_indices)} configuraciones de {nombre} no superan {max_precision*100}% de precisi√≥n")  # ...avisa al usuario.
            valid_indices = valid_indices if valid_indices else list(range(len(results['mean_test_score'])))  # Si no hay ninguna v√°lida, se usan todas como alternativa.

        # Ordenar por precisi√≥n y tomar los mejores n
        valid_scores = [(results['mean_test_score'][i], i) for i in valid_indices]  # Crea una lista de tuplas (precisi√≥n, √≠ndice) para los modelos v√°lidos.
        valid_scores.sort(reverse=True)                                             # Ordena de mayor a menor precisi√≥n.
        sorted_indices = [idx for _, idx in valid_scores[:n]]                       # Toma los √≠ndices de los mejores n modelos dentro del l√≠mite.

    else:
        # Para regresi√≥n log√≠stica, usar el comportamiento original
        sorted_indices = np.argsort(results['rank_test_score'])[:n]                # Para otros modelos (como regresi√≥n log√≠stica), toma los top n mejores seg√∫n ranking de GridSearch.

    print(f"\n\n Top {min(len(sorted_indices), n)} resultados para {nombre} (m√°x. {max_precision*100}% precisi√≥n):")  # Imprime cu√°ntos modelos se mostrar√°n y su restricci√≥n.

    for rank, idx in enumerate(sorted_indices, start=1):                           # Itera sobre los √≠ndices ordenados, con numeraci√≥n desde 1.
        params = results['params'][idx]                                            # Obtiene los hiperpar√°metros de la configuraci√≥n actual.
        cv_precision = results['mean_test_score'][idx]                             # Obtiene la precisi√≥n media en validaci√≥n cruzada.

        # Seg√∫n el nombre del modelo, instancia el clasificador con esos hiperpar√°metros
        if nombre == "Regresi√≥n Log√≠stica":
            modelo = LogisticRegression(**params, random_state=42)                # Crea modelo de regresi√≥n log√≠stica con los par√°metros y semilla fija.
        elif nombre == "KNN":
            modelo = KNeighborsClassifier(**params)                               # Crea modelo KNN con los par√°metros seleccionados.
        elif nombre == "Random Forest":
            modelo = RandomForestClassifier(**params, random_state=42)            # Crea modelo Random Forest con los par√°metros y semilla fija.
        else:
            continue                                                               # Si el nombre no coincide con ninguno conocido, omite la iteraci√≥n.

        modelo.fit(X_train, y_train)                                               # Entrena el modelo con el conjunto de entrenamiento.

        y_pred = modelo.predict(X_test)                                            # Realiza predicciones de clase sobre el conjunto de prueba.
        y_proba = modelo.predict_proba(X_test)[:, 1]                               # Obtiene las probabilidades para la clase positiva (para calcular AUC).

        print(f"\n--- {nombre} (Top #{rank}) ---")                                 # Imprime el encabezado del modelo actual en el ranking.
        print("Configuraci√≥n:", params)                                            # Muestra los hiperpar√°metros usados.
        print(f"Precisi√≥n CV: {cv_precision:.4f}")                                 # Muestra la precisi√≥n en validaci√≥n cruzada.
        print("Matriz de confusi√≥n:\n", confusion_matrix(y_test, y_pred))         # Muestra la matriz de confusi√≥n del modelo sobre el test set.
        print("Reporte de clasificaci√≥n:\n", classification_report(y_test, y_pred))  # Imprime m√©tricas detalladas: precisi√≥n, recall, F1-score.
        print("Precisi√≥n test:", accuracy_score(y_test, y_pred))                   # Imprime la precisi√≥n del modelo en el conjunto de prueba.
        print("AUC:", roc_auc_score(y_test, y_proba))                              # Imprime el √°rea bajo la curva ROC, que mide rendimiento general del clasificador.

def entrada_usuario():
    """
    Funci√≥n para predicci√≥n interactiva basada en entrada del usuario
    """
    print("\nüîé Por favor, responde las siguientes preguntas:")

    preguntas = {
        "age": "Edad (a√±os): ",
        "sex": "Sexo (1: Hombre, 0: Mujer): ",
        "cp": "Tipo de dolor en el pecho (0-3): ",
        "trestbps": "Presi√≥n arterial en reposo (mm Hg): ",
        "chol": "Colesterol s√©rico (mg/dl): ",
        "fbs": "Az√∫car en sangre en ayunas > 120 mg/dl (1: S√≠, 0: No): ",
        "restecg": "Resultados del ECG en reposo (0-2): ",
        "thalach": "Frecuencia card√≠aca m√°xima alcanzada: ",
        "exang": "Angina inducida por ejercicio (1: S√≠, 0: No): ",
        "oldpeak": "Depresi√≥n ST inducida por el ejercicio: ",
        "slope": "Pendiente del segmento ST (0-2): ",
        "ca": "N¬∫ de vasos principales coloreados (0-3): ",
        "thal": "Resultado del test Thal (1 = normal; 2 = fijo; 3 = reversible): "
    }

    valores = []                                                            # Crea una lista vac√≠a donde se guardar√°n los valores ingresados por el usuario.

    for var, pregunta in preguntas.items():                                 # Itera sobre cada par (clave, pregunta) del diccionario 'preguntas'.
        valor = float(input(pregunta))                                      # Muestra la pregunta por consola y convierte la respuesta a tipo float.
        valores.append(valor)                                               # Agrega el valor ingresado a la lista de valores.

        entrada_np = np.array(valores).reshape(1, -1)                           # Convierte la lista a un array NumPy y le da forma de una fila con muchas columnas.

        scaler = joblib.load('scaler.pkl')                                      # Carga el objeto de escalado previamente guardado (StandardScaler, por ejemplo).
        modelo = joblib.load('rf_model.pkl')                                    # Carga el modelo de Random Forest entrenado previamente.

        entrada_scaled = scaler.transform(entrada_np)                           # Escala la entrada del usuario con el mismo escalador usado en el entrenamiento.
        proba = modelo.predict_proba(entrada_scaled)[0][1]                      # Calcula la probabilidad de clase positiva (riesgo de enfermedad card√≠aca).

        if proba > 0.6:                                                         # Si la probabilidad es mayor a 60%...
            print("\nüî¥ Riesgo alto de enfermedad card√≠aca.")                    # ...se muestra un mensaje de advertencia de riesgo alto.
        else:
            print("\nüü¢ Bajo riesgo de enfermedad card√≠aca.")                    # Si no, se indica que el riesgo es bajo.

# =============================================================================
# ENTRENAMIENTO Y B√öSQUEDA DE HIPERPAR√ÅMETROS
# =============================================================================

# 6. Buscar mejores hiperpar√°metros y entrenar modelos

# Logistic Regression
log_params = {'C': np.logspace(-3, 3, 10)}                                # Define un diccionario de hiperpar√°metros para la regresi√≥n log√≠stica (valores de C en escala logar√≠tmica de 0.001 a 1000).
log_model = GridSearchCV(LogisticRegression(random_state=42), log_params, cv=5)  # Crea un GridSearchCV con validaci√≥n cruzada de 5 pliegues para buscar el mejor valor de C.
log_model.fit(X_train, y_train)                                          # Ajusta el modelo con los datos de entrenamiento.
log_best = log_model.best_estimator_                                     # Guarda el mejor modelo encontrado en la b√∫squeda de hiperpar√°metros.
log_pred = log_best.predict(X_test)                                      # Genera las predicciones del mejor modelo sobre el conjunto de prueba.
log_proba = log_best.predict_proba(X_test)[:, 1]                         # Obtiene las probabilidades de pertenecer a la clase positiva (enfermedad card√≠aca).

# KNN con restricci√≥n de precisi√≥n m√°xima del 96%
knn_params = {'n_neighbors': list(range(1, 10))}                         # Define los valores a probar para el hiperpar√°metro n_neighbors (de 1 a 9).
knn_model = GridSearchCV(KNeighborsClassifier(), knn_params, cv=30)     # Crea una b√∫squeda de hiperpar√°metros para KNN con validaci√≥n cruzada de 30 pliegues.
knn_model.fit(X_train, y_train)                                          # Entrena el modelo usando los datos de entrenamiento.

# Obtener el mejor modelo KNN que no supere 96%
knn_best, knn_best_params, knn_best_cv_score = obtener_mejor_modelo_restringido(  # Usa una funci√≥n personalizada para obtener el mejor KNN con precisi√≥n CV ‚â§ 96%.
    knn_model, "KNN", X_train, y_train, max_precision=0.96)
knn_pred = knn_best.predict(X_test)                                     # Predice las clases en el conjunto de prueba usando el mejor KNN.
knn_proba = knn_best.predict_proba(X_test)[:, 1]                         # Obtiene las probabilidades de la clase positiva.

# Random Forest con restricci√≥n de precisi√≥n m√°xima del 96%
rf_params = {'max_depth': list(range(1, 10))}                            # Define los valores a probar para la profundidad m√°xima del √°rbol (1 a 9).
rf_model = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=30)  # Crea una b√∫squeda de hiperpar√°metros para Random Forest con validaci√≥n cruzada de 30 pliegues.
rf_model.fit(X_train, y_train)                                          # Entrena el modelo Random Forest con los datos de entrenamiento.

# Obtener el mejor modelo Random Forest que no supere 96%
rf_best, rf_best_params, rf_best_cv_score = obtener_mejor_modelo_restringido(  # Usa la funci√≥n personalizada para seleccionar el mejor modelo bajo la restricci√≥n de precisi√≥n.
    rf_model, "Random Forest", X_train, y_train, max_precision=0.96)
rf_pred = rf_best.predict(X_test)                                       # Realiza predicciones sobre el conjunto de prueba con el mejor modelo.
rf_proba = rf_best.predict_proba(X_test)[:, 1]                           # Obtiene las probabilidades de clase positiva.

# =============================================================================
# EVALUACI√ìN DE MODELOS
# =============================================================================

# 7. Evaluar m√∫ltiples configuraciones con restricci√≥n de precisi√≥n
top_n_modelos_restringido(log_model, "Regresi√≥n Log√≠stica", X_train, y_train, X_test, y_test, n=4)       # Eval√∫a y muestra las 4 mejores configuraciones de regresi√≥n log√≠stica (sin restricci√≥n de precisi√≥n).
top_n_modelos_restringido(knn_model, "KNN", X_train, y_train, X_test, y_test, n=4, max_precision=0.96)    # Eval√∫a y muestra las 4 mejores configuraciones de KNN con precisi√≥n ‚â§ 96%.
top_n_modelos_restringido(rf_model, "Random Forest", X_train, y_train, X_test, y_test, n=4, max_precision=0.96)  # Eval√∫a y muestra las 4 mejores configuraciones de Random Forest con precisi√≥n ‚â§ 96%.

# Preparar probabilidades para clase 0
log_proba_0 = log_best.predict_proba(X_test)[:, 0]           # Obtiene las probabilidades de la clase 0 (sin enfermedad) para el modelo de regresi√≥n log√≠stica.
knn_proba_0 = knn_best.predict_proba(X_test)[:, 0]           # Obtiene las probabilidades de la clase 0 para el mejor modelo KNN.
rf_proba_0 = rf_best.predict_proba(X_test)[:, 0]             # Obtiene las probabilidades de la clase 0 para el mejor modelo Random Forest.

# Invertir las etiquetas: ahora la clase "0" es la positiva
y_test_invertido = 1 - y_test                                # Invierte las etiquetas reales del conjunto de prueba: ahora "0" (sin enfermedad) se considera la clase positiva.

# =============================================================================
# VISUALIZACIONES
# =============================================================================

# 8. Graficar curvas ROC para la clase 0
plt.figure(figsize=(8, 6))                                                             # Crea una nueva figura de tama√±o 8x6 para el gr√°fico.

for nombre, y_proba in zip(["Logistic Regression", "KNN", "Random Forest"],           # Itera sobre los modelos y sus probabilidades para la clase 0...
                          [log_proba_0, knn_proba_0, rf_proba_0]):
    fpr, tpr, _ = roc_curve(y_test_invertido, y_proba)                                 # Calcula tasa de falsos positivos (FPR) y verdaderos positivos (TPR) para la clase 0.
    plt.plot(fpr, tpr,                                                                 # Traza la curva ROC para cada modelo.
             label=f'{nombre} (AUC: {int(roc_auc_score(y_test_invertido, y_proba) * 100) / 100:.2f})')  # A√±ade la AUC truncada a 2 decimales como etiqueta.

plt.plot([0, 1], [0, 1], 'k--')                                                        # Traza una l√≠nea diagonal punteada como referencia (modelo aleatorio).
plt.xlabel('FPR (Clase 0)')                                                            # Etiqueta eje X: tasa de falsos positivos.
plt.ylabel('TPR (Clase 0)')                                                            # Etiqueta eje Y: tasa de verdaderos positivos.
plt.title('Curvas ROC [Clase 0]')                                                      # T√≠tulo del gr√°fico.
plt.legend()                                                                           # Muestra la leyenda con los nombres de los modelos.
plt.grid(True)                                                                         # Activa la cuadr√≠cula para facilitar la lectura.
plt.tight_layout()                                                                     # Ajusta autom√°ticamente los m√°rgenes del gr√°fico.
plt.show()                                                                             # Muestra el gr√°fico en pantalla.

# 8.1. Graficar curvas ROC para la clase 1
plt.figure(figsize=(8, 6))                                                             # Crea una nueva figura para graficar la clase 1.

for nombre, y_proba in zip(["Logistic Regression", "KNN", "Random Forest"], 
                          [log_proba, knn_proba, rf_proba]):                           # Itera sobre los modelos y sus probabilidades para la clase 1.
    fpr, tpr, _ = roc_curve(y_test, y_proba)                                           # Calcula FPR y TPR usando las etiquetas originales (clase 1 como positiva).
    plt.plot(fpr, tpr,                                                                 # Traza la curva ROC...
             label=f'{nombre} (AUC: {int(roc_auc_score(y_test, y_proba) * 100) / 100:.2f})')  # ...con AUC truncada en la etiqueta.

plt.plot([0, 1], [0, 1], 'k--')                                                        # L√≠nea de referencia diagonal (modelo aleatorio).
plt.xlabel('FPR (Clase 1)')                                                            # Etiqueta del eje X.
plt.ylabel('TPR (Clase 1)')                                                            # Etiqueta del eje Y.
plt.title('Curvas ROC [Clase 1]')                                                      # T√≠tulo del gr√°fico.
plt.legend()                                                                           # Muestra la leyenda de los modelos.
plt.grid(True)                                                                         # Activa cuadr√≠cula.
plt.tight_layout()                                                                     # Ajusta m√°rgenes autom√°ticamente.
plt.show()                                                                             # Muestra el gr√°fico.

# 8.2 Curvas ROC para KNN (mejores modelos)
fpr_knn, tpr_knn, _ = roc_curve(y_test, knn_proba)                                     # Calcula FPR y TPR para la clase 1 usando el mejor modelo KNN.
roc_auc_knn = auc(fpr_knn, tpr_knn)                                                    # Calcula el √°rea bajo la curva (AUC) para clase 1.

fpr_knn_0, tpr_knn_0, _ = roc_curve(y_test_invertido, knn_proba_0)                     # Calcula FPR y TPR para la clase 0.
roc_auc_knn_0 = auc(fpr_knn_0, tpr_knn_0)                                               # Calcula AUC para la clase 0.

plt.figure(figsize=(8, 6))                                                             # Crea una nueva figura para graficar ambas curvas del KNN.
plt.plot(fpr_knn, tpr_knn, label=f'Clase 1 (AUC = {roc_auc_knn:.2f})')                 # Traza curva ROC para clase 1 y muestra su AUC.
plt.plot(fpr_knn_0, tpr_knn_0, label=f'Clase 0 (AUC = {roc_auc_knn_0:.2f})')           # Traza curva ROC para clase 0 con su AUC.
plt.plot([0, 1], [0, 1], 'k--')                                                        # L√≠nea diagonal de referencia.
plt.xlabel('FPR')                                                                      # Etiqueta eje X (general).
plt.ylabel('TPR')                                                                      # Etiqueta eje Y.
plt.title(f'Curvas ROC del mejor modelo KNN (Restricci√≥n 96%) - {knn_best_params}')   # T√≠tulo con hiperpar√°metros del mejor modelo KNN.
plt.legend(loc='lower right')                                                          # Muestra leyenda abajo a la derecha.
plt.grid(True)                                                                         # Cuadr√≠cula activada.
plt.tight_layout()                                                                     # Ajuste autom√°tico de m√°rgenes.
plt.show()                                                                             # Muestra el gr√°fico.

# 8.3 Curvas ROC para Random Forest (mejores modelos)
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_proba)                                # Calcula FPR y TPR para la clase 1 (enfermedad) con el modelo Random Forest.
roc_auc_rf = auc(fpr_rf, tpr_rf)                                               # Calcula el √°rea bajo la curva (AUC) para la clase 1.

fpr_rf_0, tpr_rf_0, _ = roc_curve(y_test_invertido, rf_proba_0)                # Calcula FPR y TPR para la clase 0 (sanos) usando etiquetas invertidas.
roc_auc_rf_0 = auc(fpr_rf_0, tpr_rf_0)                                         # Calcula AUC para la clase 0.

plt.figure(figsize=(8, 6))                                                     # Crea una nueva figura para el gr√°fico.
plt.plot(fpr_rf, tpr_rf, label=f'Clase 1 (AUC = {roc_auc_rf:.2f})')            # Dibuja curva ROC para clase 1.
plt.plot(fpr_rf_0, tpr_rf_0, label=f'Clase 0 (AUC = {roc_auc_rf_0:.2f})')      # Dibuja curva ROC para clase 0.
plt.plot([0, 1], [0, 1], 'k--')                                                # L√≠nea diagonal como referencia (modelo aleatorio).
plt.xlabel('FPR')                                                              # Etiqueta del eje X.
plt.ylabel('TPR')                                                              # Etiqueta del eje Y.
plt.title(f'Curvas ROC del mejor modelo Random Forest (Restricci√≥n 96%) - {rf_best_params}')  # T√≠tulo del gr√°fico con los par√°metros √≥ptimos.
plt.legend(loc='lower right')                                                  # Coloca leyenda en la esquina inferior derecha.
plt.grid(True)                                                                 # Activa la cuadr√≠cula.
plt.tight_layout()                                                             # Ajusta m√°rgenes autom√°ticamente.
plt.show()                                                                     # Muestra el gr√°fico.

# 8.4 Curvas ROC para Regresi√≥n Log√≠stica
fpr_log, tpr_log, _ = roc_curve(y_test, log_proba)                             # Calcula FPR y TPR para clase 1 con regresi√≥n log√≠stica.
roc_auc_log = auc(fpr_log, tpr_log)                                            # Calcula AUC para clase 1.

fpr_log_0, tpr_log_0, _ = roc_curve(y_test_invertido, log_proba_0)            # Calcula FPR y TPR para clase 0 con etiquetas invertidas.
roc_auc_log_0 = auc(fpr_log_0, tpr_log_0)                                     # Calcula AUC para clase 0.

plt.figure(figsize=(8, 6))                                                     # Nueva figura.
plt.plot(fpr_log, tpr_log, label=f'Clase 1 (AUC = {roc_auc_log:.2f})')        # Dibuja curva ROC para clase 1.
plt.plot(fpr_log_0, tpr_log_0, label=f'Clase 0 (AUC = {roc_auc_log_0:.2f})')  # Dibuja curva ROC para clase 0.
plt.plot([0, 1], [0, 1], 'k--')                                                # L√≠nea aleatoria de referencia.
plt.xlabel('FPR')                                                              # Etiqueta eje X.
plt.ylabel('TPR')                                                              # Etiqueta eje Y.
plt.title('Curvas ROC del mejor modelo Regresi√≥n Log√≠stica')                  # T√≠tulo del gr√°fico.
plt.legend(loc='lower right')                                                  # Leyenda abajo a la derecha.
plt.grid(True)                                                                 # Activa cuadr√≠cula.
plt.tight_layout()                                                             # Ajusta el dise√±o.
plt.show()                                                                     # Muestra el gr√°fico.

# 9. Matrices de confusi√≥n heatmap
modelos = [("Logistic Regression", log_pred), ("KNN (‚â§96%)", knn_pred), ("Random Forest (‚â§96%)", rf_pred)]  # Lista de tuplas con nombre del modelo y sus predicciones.

for nombre, pred in modelos:                                                   # Itera sobre cada modelo y sus predicciones.
    plt.figure()                                                               # Crea una nueva figura para cada matriz.
    sns.heatmap(confusion_matrix(y_test, pred),                               # Dibuja la matriz de confusi√≥n como un heatmap.
                annot=True, fmt='d', cmap='Blues')                            # Muestra los n√∫meros en cada celda, con color azul.
    plt.title(f'Matriz de Confusi√≥n - {nombre}')                              # T√≠tulo del gr√°fico.
    plt.xlabel('Predicci√≥n')                                                  # Etiqueta del eje X.
    plt.ylabel('Real')                                                        # Etiqueta del eje Y.
    plt.tight_layout()                                                        # Ajuste autom√°tico del dise√±o.
    plt.show()                                                                # Muestra el gr√°fico.


# 10. Curvas de precisi√≥n vs hiperpar√°metros

# KNN - Mostrar solo configuraciones que no superen 96%
plt.figure()                                                                # Crea una nueva figura para graficar.
knn_scores = knn_model.cv_results_['mean_test_score']                      # Obtiene las precisiones promedio de cada configuraci√≥n KNN.
knn_params_values = knn_params['n_neighbors']                              # Obtiene la lista de valores de K probados.

# Filtrar valores que no superen 96%
knn_filtered_scores = []                                                   # Lista para almacenar precisiones ‚â§ 96%.
knn_filtered_params = []                                                   # Lista para almacenar valores de K correspondientes.
for i, (param, score) in enumerate(zip(knn_params_values, knn_scores)):    # Itera sobre pares (K, precisi√≥n).
    if score <= 0.96:                                                      # Si la precisi√≥n es menor o igual a 96%...
        knn_filtered_params.append(param)                                 # Guarda el valor de K.
        knn_filtered_scores.append(score)                                 # Guarda la precisi√≥n.

plt.plot(knn_filtered_params, knn_filtered_scores, marker='o', label='‚â§96% precisi√≥n')  # Grafica solo las precisiones bajo 96% con c√≠rculos.
plt.plot(knn_params_values, knn_scores, marker='x', alpha=0.5, label='Todos los valores')  # Grafica todas las precisiones con cruces y transparencia.

# Marcar el mejor modelo seleccionado
if knn_best_params['n_neighbors'] in knn_filtered_params:                  # Si el mejor KNN seleccionado est√° en los filtrados...
    best_score = knn_scores[knn_params_values.index(knn_best_params['n_neighbors'])]  # Obtiene su precisi√≥n.
    plt.plot(knn_best_params['n_neighbors'], best_score, marker='*', markersize=15,  # Lo marca en la gr√°fica con una estrella roja grande.
             color='red', label=f'Mejor seleccionado (k={knn_best_params["n_neighbors"]})')

plt.title("Precisi√≥n KNN vs K (con restricci√≥n 96%)")                      # T√≠tulo del gr√°fico.
plt.xlabel("Valores de K")                                                 # Etiqueta eje X.
plt.ylabel("Precisi√≥n")                                                    # Etiqueta eje Y.
plt.axhline(y=0.96, color='r', linestyle='--', label='L√≠mite 96%')          # Dibuja l√≠nea horizontal roja en y=0.96 como referencia.
plt.legend()                                                              # Muestra leyenda.
plt.grid(True)                                                            # Activa cuadr√≠cula.
plt.tight_layout()                                                        # Ajusta m√°rgenes.
plt.show()                                                              # Muestra el gr√°fico.


# Random Forest - Mostrar solo configuraciones que no superen 96%
plt.figure()                                                               # Nueva figura para Random Forest.
rf_scores = rf_model.cv_results_['mean_test_score']                       # Obtiene precisiones promedio de cada configuraci√≥n de Random Forest.
rf_params_values = rf_params['max_depth']                                # Lista de valores de profundidad m√°xima probados.

# Filtrar valores que no superen 96%
rf_filtered_scores = []                                                   # Lista para precisiones ‚â§ 96%.
rf_filtered_params = []                                                   # Lista para profundidades correspondientes.
for i, (param, score) in enumerate(zip(rf_params_values, rf_scores)):     # Itera por pares (profundidad, precisi√≥n).
    if score <= 0.96:                                                     # Si precisi√≥n ‚â§ 96%...
        rf_filtered_params.append(param)                                 # Guarda profundidad.
        rf_filtered_scores.append(score)                                 # Guarda precisi√≥n.

plt.plot(rf_filtered_params, rf_filtered_scores, marker='o', color='green', label='‚â§96% precisi√≥n')  # Grafica puntos verdes para precisiones bajo 96%.
plt.plot(rf_params_values, rf_scores, marker='x', color='green', alpha=0.5, label='Todos los valores')  # Grafica todas precisiones con cruces verdes y transparencia.

# Marcar el mejor modelo seleccionado
if rf_best_params['max_depth'] in rf_filtered_params:                    # Si el mejor par√°metro est√° entre los filtrados...
    best_score = rf_scores[rf_params_values.index(rf_best_params['max_depth'])]  # Obtiene la precisi√≥n del mejor modelo.
    plt.plot(rf_best_params['max_depth'], best_score, marker='*', markersize=15,    # Marca el punto con estrella roja grande.
             color='red', label=f'Mejor seleccionado (depth={rf_best_params["max_depth"]})')

plt.title("Precisi√≥n RF vs Max Depth (con restricci√≥n 96%)")              # T√≠tulo del gr√°fico.
plt.xlabel("Profundidad m√°xima")                                         # Etiqueta eje X.
plt.ylabel("Precisi√≥n")                                                  # Etiqueta eje Y.
plt.axhline(y=0.96, color='r', linestyle='--', label='L√≠mite 96%')        # L√≠nea horizontal roja en 0.96.
plt.legend()                                                            # Muestra leyenda.
plt.grid(True)                                                          # Activa cuadr√≠cula.
plt.tight_layout()                                                    # Ajusta m√°rgenes.
plt.show()                                                          # Muestra el gr√°fico.

# Regresi√≥n Log√≠stica (sin restricci√≥n)
accuracies_test = []                                                        # Inicializa una lista vac√≠a para guardar las precisiones en test.

for c in log_params['C']:                                                   # Itera sobre cada valor de C definido en log_params.
    model = LogisticRegression(C=c, max_iter=1000)                          # Crea un modelo de regresi√≥n log√≠stica con el par√°metro C actual y m√°ximo de 1000 iteraciones.
    model.fit(X_train, y_train)                                             # Entrena el modelo con los datos de entrenamiento.
    acc = accuracy_score(y_test, model.predict(X_test))                     # Calcula la precisi√≥n del modelo usando las predicciones sobre el conjunto de prueba.
    accuracies_test.append(acc)                                             # A√±ade la precisi√≥n calculada a la lista accuracies_test.

plt.figure()                                                               # Crea una nueva figura para el gr√°fico.
plt.plot(log_params['C'], accuracies_test, marker='o', color='red')        # Dibuja una curva de precisi√≥n vs valor de C con marcadores rojos.
plt.xscale('log')                                                          # Establece escala logar√≠tmica en el eje X (para los valores de C).
plt.title("Precisi√≥n Regresi√≥n Log√≠stica vs C")                           # A√±ade t√≠tulo al gr√°fico.
plt.xlabel("Valores de C (log)")                                           # Etiqueta el eje X.
plt.ylabel("Precisi√≥n")                                                    # Etiqueta el eje Y.
plt.grid(True)                                                             # Activa la cuadr√≠cula para mejor visualizaci√≥n.
plt.tight_layout()                                                         # Ajusta el dise√±o para que no se corten elementos.
plt.show()                                                                 # Muestra el gr√°fico en pantalla.

# =============================================================================
# GUARDADO DE MODELOS Y AN√ÅLISIS FINAL
# =============================================================================

# 11. Guardar mejor modelo y scaler
joblib.dump(rf_best, 'rf_model.pkl')                      # Guarda el mejor modelo Random Forest entrenado en un archivo llamado 'rf_model.pkl'.
joblib.dump(scaler, 'scaler.pkl')                         # Guarda el objeto scaler (normalizador) en un archivo llamado 'scaler.pkl'.

print(f"\n‚úÖ Modelo Random Forest guardado con restricci√≥n 96%:")  # Imprime mensaje confirmando que el modelo se guard√≥ correctamente.
print(f"Par√°metros: {rf_best_params}")                               # Muestra los par√°metros del mejor modelo Random Forest guardado.
print(f"Precisi√≥n CV: {rf_best_cv_score:.4f}")                       # Muestra la precisi√≥n promedio en validaci√≥n cruzada con 4 decimales.
print(f"Precisi√≥n Test: {accuracy_score(y_test, rf_pred):.4f}")     # Muestra la precisi√≥n obtenida en el conjunto de prueba con 4 decimales.

# 12. Predicci√≥n interactiva (descomenta para usar)
# entrada_usuario()

# =============================================================================
# AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS
# =============================================================================

print("\n" + "="*60)                                              # Imprime una l√≠nea de 60 signos "=" para separar visualmente.
print("üìä AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS")           # Imprime t√≠tulo del an√°lisis con emoji.
print("="*60)                                                    # Imprime otra l√≠nea de separaci√≥n.

print("\n7Ô∏è‚É£ CORRELACI√ìN ABSOLUTA CON LA VARIABLE OBJETIVO:")     # Imprime subt√≠tulo para esta secci√≥n del an√°lisis.
print("-" * 50)                                                  # Imprime una l√≠nea de 50 guiones para separar visualmente.

# Calcular correlaci√≥n absoluta con la variable objetivo
correlations = X.corrwith(y).abs().sort_values(ascending=False)  # Calcula la correlaci√≥n entre cada caracter√≠stica (columna de X) y la variable objetivo y, toma el valor absoluto y ordena de mayor a menor.
correlation_df = pd.DataFrame({                                  # Crea un DataFrame para organizar los resultados.
    'Caracter√≠stica': correlations.index,                       # Columna con nombres de las caracter√≠sticas.
    'Correlaci√≥n_Abs': correlations.values,                     # Columna con los valores absolutos de correlaci√≥n.
    'Porcentaje_Corr': (correlations.values / correlations.sum()) * 100  # Calcula el porcentaje que representa cada correlaci√≥n respecto al total de correlaciones absolutas.
})

# Mostrar correlaciones con target
print("Correlaci√≥n absoluta con variable objetivo:")            # Imprime encabezado antes de listar resultados.
for i, row in correlation_df.iterrows():                        # Itera sobre cada fila del DataFrame de correlaciones.
    print(f"{i+1:2d}. {row['Caracter√≠stica']:12s} - {row['Correlaci√≥n_Abs']:.3f} ({row['Porcentaje_Corr']:5.2f}%)")  # Imprime √≠ndice, nombre caracter√≠stica, correlaci√≥n absoluta con 3 decimales y porcentaje con 2 decimales.

print("\n" + "="*60)                                            # Imprime l√≠nea de separaci√≥n.
print("‚úÖ AN√ÅLISIS COMPLETADO")                                  # Mensaje indicando que el an√°lisis termin√≥.
print("="*60)                                                   # Otra l√≠nea de separaci√≥n.